{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZM4-NOC1JeZ"
      },
      "outputs": [],
      "source": [
        "import arviz as az\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pymc as pm\n",
        "import pytensor.tensor as pt\n",
        "import re\n",
        "\n",
        "import time\n",
        "\n",
        "from pathlib import Path\n",
        "from scipy.stats import norm\n",
        "from scipy.stats import gamma\n",
        "from scipy.stats import beta\n",
        "from scipy.stats import truncnorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Gy5YfwHKlTb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLjVXggwJvji"
      },
      "source": [
        "# Generación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omXT2pMCKW7K"
      },
      "source": [
        "### Funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlZs6rrFxwQe"
      },
      "outputs": [],
      "source": [
        "def parametros(dist, *args, shift=0, inv=0, lim_inf=None, lim_sup=None):\n",
        "\n",
        "    params = {\"dist\": dist}\n",
        "    for i, value in enumerate(args, start=1):\n",
        "        params[f\"param{i}\"] = value\n",
        "    params[\"lim_inf\"] = lim_inf\n",
        "    params[\"lim_sup\"] = lim_sup\n",
        "\n",
        "    return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zidS3v2troiL"
      },
      "outputs": [],
      "source": [
        "def dist_muestras(paramsY, var='Y', n_muestras=1000, random_seed = None):\n",
        "\n",
        "    dist = paramsY.get('dist')\n",
        "\n",
        "    rng = np.random.default_rng(seed=random_seed)\n",
        "    if dist == 'uniforme':\n",
        "      data = rng.uniform(low=paramsY.get('param1'), high=paramsY.get('param2'), size=n_muestras)\n",
        "    elif dist == 'normal':\n",
        "      data = rng.normal(loc=paramsY.get('param1'), scale=paramsY.get('param2'), size=n_muestras)\n",
        "    elif dist == 'halfnormal':\n",
        "      data = np.abs(rng.normal(loc=paramsY.get('param1'), scale=paramsY.get('param2'), size=n_muestras))\n",
        "    elif dist == 'gamma':\n",
        "      data = rng.gamma(shape=paramsY.get('param1'), scale=paramsY.get('param2'), size=n_muestras)\n",
        "    elif dist == 'beta':\n",
        "      data = rng.beta(a=paramsY.get('param1'), b=paramsY.get('param2'), size=n_muestras)\n",
        "    else:\n",
        "        raise ValueError(f\"Distribución '{dist}' no contemplada.\")\n",
        "\n",
        "    return pd.DataFrame({var: data})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc3cDwk4-V8o"
      },
      "outputs": [],
      "source": [
        "def muestreo(paramsY, var='Y', n_muestras=1000, random_seed = None):\n",
        "\n",
        "  df = dist_muestras(paramsY, var, n_muestras, random_seed)\n",
        "\n",
        "  a = paramsY.get('lim_inf')\n",
        "  b = paramsY.get('lim_sup')\n",
        "  if a is None:\n",
        "    a = df[var].min()\n",
        "  if b is None:\n",
        "    b = df[var].max()\n",
        "\n",
        "  if a <= b:\n",
        "    while (df[var] < a).any() or (df[var] > b).any():\n",
        "      n_aux = len(df[(df[var] < a) | (df[var] > b)])\n",
        "      df_aux = dist_muestras(paramsY, var, n_aux, random_seed)\n",
        "      df = pd.concat([df[(df[var] >= a) & (df[var] <= b)], df_aux], ignore_index=True)\n",
        "  else:\n",
        "    while ((df[var] < b) & (df[var] > a)).any():\n",
        "      n_aux = ((df[var] > a) & (df[var] < b)).sum()\n",
        "      df_aux = dist_muestras(paramsY, var, n_aux, random_seed)\n",
        "      df = pd.concat([df[(df[var] >= a) & (df[var] <= b)], df_aux], ignore_index=True)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xraZXVwSskJ0"
      },
      "source": [
        "### Selección de muestras registradas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsVx7LonwTob"
      },
      "outputs": [],
      "source": [
        "# modificar para incluir límites\n",
        "def R_mid_Y(data, paramsR, var='Y', random_seed = None) -> np.ndarray:\n",
        "\n",
        "    dist = paramsR.get('dist')\n",
        "    rng = np.random.default_rng(seed=random_seed)\n",
        "    x = data[var].values\n",
        "\n",
        "    if dist == 'uniforme':\n",
        "        a = paramsR.get('param1', x.min())\n",
        "        b = paramsR.get('param2', x.max())\n",
        "        p = paramsR.get('param3', 1.0)\n",
        "        probs = np.where((x >= a) & (x <= b), p, 0.0)\n",
        "\n",
        "    elif dist == 'normal':\n",
        "        loc = paramsR.get('param1', np.mean(x))\n",
        "        scale = paramsR.get('param2', np.std(x) + 1e-9)\n",
        "        a = paramsR.get('lim_inf', None)\n",
        "        b = paramsR.get('lim_sup', None)\n",
        "        if a is None and b is None:\n",
        "          probs = norm.pdf(x, loc=loc, scale=scale)\n",
        "          probs = probs / (probs.max() + 1e-9)\n",
        "        else:\n",
        "          if a is None:\n",
        "            a = x.min()\n",
        "          if b is None:\n",
        "            b = x.max()\n",
        "          probs = truncnorm.pdf(x, a=(a-loc)/scale, b=(b-loc)/scale)\n",
        "\n",
        "    elif dist == 'halfnormal':\n",
        "        scale = paramsR.get('param1', np.std(x) + 1e-9)\n",
        "        probs = norm.pdf(x, loc=0, scale=scale)\n",
        "        probs = probs / (probs.max() + 1e-9)\n",
        "        probs[x < 0] = 0\n",
        "\n",
        "    elif dist == 'beta':\n",
        "        a = paramsR.get('param1', 2)\n",
        "        b = paramsR.get('param2', 5)\n",
        "        x_norm = (x - x.min()) / (x.max() - x.min() + 1e-9)\n",
        "        probs = beta.pdf(x_norm, a, b)\n",
        "        probs = probs / (probs.max() + 1e-9)\n",
        "\n",
        "    elif dist == 'gamma':\n",
        "        shape = paramsR.get('param1', 2.0)   # k\n",
        "        scale = paramsR.get('param2', 1.0)   # θ\n",
        "        probs = gamma.pdf(x, a=shape, scale=scale)\n",
        "        probs = probs / (probs.max() + 1e-9)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Distribución '{dist}' no contemplada.\")\n",
        "\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1vWQRrlONKK"
      },
      "outputs": [],
      "source": [
        "# Muestras observadas\n",
        "def datos_seleccion(dist_original, dist_registro, var='Y', n_muestras=1000, random_seed=None):\n",
        "\n",
        "    # Generar datos originales Y\n",
        "    datos_originales = muestreo(dist_original, var, n_muestras, random_seed)\n",
        "    # Generar probabilidad R condicionada por Y\n",
        "    func_registro = R_mid_Y(datos_originales, dist_registro)\n",
        "    # Generar patrón de registro\n",
        "    rng = np.random.default_rng(seed=random_seed)\n",
        "    indicatriz = rng.binomial(n=1, p=func_registro)\n",
        "\n",
        "    indices_registrados = (indicatriz == 1)\n",
        "    datos_completos = pd.DataFrame({var: datos_originales[var],\"R\": indicatriz})\n",
        "\n",
        "    return datos_completos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fkTgt6ptgsA"
      },
      "source": [
        "### Mezcla de muestras registradas y no registradas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoRaf3qWh7Su"
      },
      "outputs": [],
      "source": [
        "def datos_mezcla(ProbR, var, dist_R, dist_noR, n_muestras=1000, random_seed=None):\n",
        "\n",
        "    rng = np.random.default_rng(seed=random_seed)\n",
        "    indicatriz = rng.binomial(n=1, p=ProbR, size=n_muestras)\n",
        "\n",
        "    n_R = (indicatriz == 1).sum()\n",
        "    n_noR = (indicatriz == 0).sum()\n",
        "\n",
        "    dist_YR = muestreo(dist_R, var, n_R, random_seed)[var].values\n",
        "    dist_YnoR = muestreo(dist_noR, var, n_noR, random_seed)[var].values\n",
        "\n",
        "    datos_originales = []\n",
        "    i_R, i_noR = 0, 0\n",
        "    for r in indicatriz:\n",
        "        if r == 1:\n",
        "            datos_originales.append(dist_YR[i_R])\n",
        "            i_R += 1\n",
        "        else:\n",
        "            datos_originales.append(dist_YnoR[i_noR])\n",
        "            i_noR += 1\n",
        "\n",
        "    indices_registrados = (indicatriz == 1)\n",
        "    datos_completos = pd.DataFrame({var: datos_originales, \"R\": indicatriz})\n",
        "\n",
        "    return datos_completos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1ZusgCO3yrc"
      },
      "source": [
        "### Ejecución con datos de .csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_OdxrkM1cEb"
      },
      "outputs": [],
      "source": [
        "def genera_datos(input_path=None, input_dict=None, df=None, pct=0.15, n_muestras=1000, indicador_R=0):\n",
        "\n",
        "    if df is None:\n",
        "      if input_path is None:\n",
        "        df = pd.DataFrame([input_dict])\n",
        "      else:\n",
        "        df = pd.read_csv(input_path)\n",
        "        input_path = Path(input_path)\n",
        "        output_dir = input_path.parent / 'Datos_generados'\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        observed_dir = input_path.parent / 'Datos_observados'\n",
        "        observed_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "\n",
        "        sim_id = row['sim_id']\n",
        "        method = row['method'].lower()\n",
        "\n",
        "        dist_1 = parametros(row['dist_1'],row['dist_1_param_1'],row['dist_1_param_2'],row['lim_inf'],row['lim_sup'])\n",
        "        dist_2 = parametros(row['dist_2'],row['dist_2_param_1'],row['dist_2_param_2'],row['lim_inf'],row['lim_sup'])\n",
        "\n",
        "        if method == 'mezcla':\n",
        "            P_R = row['P_R']\n",
        "            YR = datos_mezcla(P_R, 'Y', dist_1, dist_2, n_muestras=n_muestras)\n",
        "\n",
        "        elif method == 'seleccion':\n",
        "            YR = datos_seleccion(dist_1, dist_2, n_muestras=n_muestras)\n",
        "\n",
        "        if input_path is None and indicador_R==0:\n",
        "          return YR\n",
        "\n",
        "        elif input_path is None and indicador_R==1:\n",
        "          return YR[['Y','R']]\n",
        "\n",
        "        else:\n",
        "          for col, value in row.items():\n",
        "              YR[col] = value\n",
        "\n",
        "          output_path = output_dir / f\"{sim_id}.csv\"\n",
        "          YR.to_csv(output_path, index=False)\n",
        "\n",
        "          YR_seg = YR.copy()\n",
        "          idx_R = YR_seg.columns.get_loc(\"R\")\n",
        "          YR_seg.insert((idx_R) + 1, \"S\", YR_seg[\"R\"])\n",
        "          idx_aus = YR_seg.index[YR_seg[\"S\"] == 0]\n",
        "          len_aus = len(idx_aus)\n",
        "          idx_flip = np.random.choice(idx_aus, size=int(pct*len_aus), replace=False)\n",
        "          YR_seg.loc[idx_flip, \"S\"] = 1\n",
        "          seguimiento_path = output_dir / f\"{sim_id}_seg.csv\"\n",
        "          YR_seg.to_csv(seguimiento_path, index=False)\n",
        "\n",
        "          YR_obs = YR.loc[YR[\"R\"] == 1, \"Y\"]\n",
        "          YR_obs.to_csv(observed_dir / f\"{sim_id}.csv\", index=False)\n",
        "\n",
        "          YR_obs_seg = YR_seg.loc[(YR_seg[\"R\"] == 0) & (YR_seg[\"S\"] == 1), \"Y\"]\n",
        "          YR_obs_seg.to_csv(observed_dir / f\"{sim_id}_seg.csv\", index=False)\n",
        "\n",
        "        return YR[['Y','R']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72ihOUL6qV7h"
      },
      "source": [
        "# Modelado\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxii22hqtxXe"
      },
      "source": [
        "## Modelado de la distribución conjunta $(Y,R)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ8lzWvVcgew"
      },
      "outputs": [],
      "source": [
        "def prior_theta(nombre, prior):\n",
        "\n",
        "    dist = prior.get('dist')\n",
        "\n",
        "    # Prior no informativa\n",
        "    if dist == \"flat\":\n",
        "        return pm.Flat(nombre)\n",
        "\n",
        "    # Si puedo acotar theta\n",
        "    elif dist == \"uniforme\":\n",
        "        lower = prior.get('lower', prior.get('param1'))\n",
        "        upper = prior.get('upper', prior.get('param2'))\n",
        "        if lower is None or upper is None:\n",
        "            raise ValueError(f\"Uniform prior '{nombre}' requires 'lower' and 'upper'\")\n",
        "        return pm.Uniform(nombre, lower=lower, upper=upper)\n",
        "\n",
        "    # Si es necesariamente positiva\n",
        "    elif dist == \"halfnormal\":\n",
        "        sigma = prior.get('sigma', prior.get('param1'))\n",
        "        if sigma is None:\n",
        "            raise ValueError(f\"HalfNormal prior '{nombre}' requires 'sigma'\")\n",
        "        return pm.HalfNormal(nombre, sigma=sigma)\n",
        "\n",
        "    # Si tengo una idea aproximada de cuál es el valor esperado\n",
        "    elif dist == \"normal\":\n",
        "        mu = prior.get('mu', prior.get('param1'))\n",
        "        sigma = prior.get('sigma', prior.get('param2'))\n",
        "        if mu is None or sigma is None:\n",
        "            raise ValueError(f\"Normal prior '{nombre}' requires 'mu' and 'sigma'\")\n",
        "        return pm.Normal(nombre, mu=mu, sigma=sigma)\n",
        "    else:\n",
        "        raise ValueError(f\"Distribución a priori no reconocida: {dist}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jofy7LaZuCO8"
      },
      "source": [
        "### Modelo de mezcla de patrones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWZX0qkX5X6o"
      },
      "outputs": [],
      "source": [
        "def Dist_Y(valores, var, hipY, theta1=None, theta2=None, lim_inf=None, lim_sup=None):\n",
        "\n",
        "  if hipY == 'uniforme':\n",
        "    return pm.Uniform(var, lower=theta1, upper=theta2, observed=valores)\n",
        "  elif hipY == 'normal':\n",
        "    return pm.Normal(var, mu=theta1, sigma=theta2, observed=valores)\n",
        "  elif hipY == 'TruncNormal':\n",
        "    return pm.TruncatedNormal(var, mu=theta1,sigma=theta2, lower=lim_inf, upper=lim_sup, observed=valores)\n",
        "  elif hipY == 'HalfNormal':\n",
        "    return pm.HalfNormal(var, sigma=theta1, observed=valores)\n",
        "  elif hipY == 'gamma':\n",
        "    return pm.Gamma(var, alpha=theta1, beta=1/theta2, observed=valores)\n",
        "  elif hipY == 'beta':\n",
        "    return pm.Beta(var, alpha=theta1, beta=theta2, observed=valores)\n",
        "  else:\n",
        "    raise ValueError(f\"Distribución {hipY} no contemplada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaHjMX2vpjxX"
      },
      "outputs": [],
      "source": [
        "def EstimaMezcla(df, hipYobs, hipYaus, dicPriors, dicPosteriors=None,\n",
        "                 var='Y', lim_inf=None, lim_sup=None, seguimiento=0, df_seg=None, show=0):\n",
        "\n",
        "    if seguimiento == 0:\n",
        "        priors_iter = list(dicPriors.items())[:2]\n",
        "    else:\n",
        "        priors_iter = list(dicPriors.items())\n",
        "\n",
        "    with pm.Model() as modelo:\n",
        "\n",
        "        theta = []\n",
        "        theta_dict = {}\n",
        "\n",
        "        for i, (nombre, prior) in enumerate(priors_iter):\n",
        "            if isinstance(prior, (int, float, np.number)):\n",
        "                theta_i = prior  # Treat as constant\n",
        "            elif dicPosteriors and nombre in dicPosteriors:\n",
        "                muestras_aux = dicPosteriors[nombre].values.reshape(-1)\n",
        "                muestras_i = pm.math.constant(muestras_aux)\n",
        "                aux_i = pm.Categorical(f'{nombre}_aux', p=np.ones(len(muestras_aux)) / len(muestras_aux))\n",
        "                theta_i = pm.Deterministic(nombre, muestras_i[aux_i])\n",
        "            else:\n",
        "                theta_i = prior_theta(nombre, prior)\n",
        "\n",
        "            theta.append(theta_i)\n",
        "            theta_dict[nombre] = theta_i\n",
        "\n",
        "\n",
        "        # Determine observed data based on seguimiento\n",
        "        if seguimiento == 0:\n",
        "            registro = df[var].values\n",
        "            verosimilitud = Dist_Y(registro, var , hipYobs, theta1=theta[0], theta2=theta[1], lim_inf=lim_inf, lim_sup=lim_sup)\n",
        "\n",
        "        elif seguimiento == 1:\n",
        "            registro_obs = df[var].values\n",
        "            verosimilitud_obs = Dist_Y(registro_obs, 'Y_obs' , hipYobs, theta1=theta[0], theta2=theta[1], lim_inf=lim_inf, lim_sup=lim_sup)\n",
        "\n",
        "            registro_aus = df_seg[var].values\n",
        "            verosimilitud_aus = Dist_Y(registro_aus, 'Y_aus' , hipYaus, theta1=theta[2], theta2=theta[3], lim_inf=lim_inf, lim_sup=lim_sup)\n",
        "\n",
        "        # Sample posterior\n",
        "        muestras_posterior = pm.sample(init=\"adapt_diag\", progressbar=True, return_inferencedata=True, tune=1000, draws = 1000)\n",
        "\n",
        "    return muestras_posterior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rumhEjzHuCGm"
      },
      "source": [
        "### Modelo de selección"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "io4Wn-EfR4Wd"
      },
      "outputs": [],
      "source": [
        "# Hipótesis sobre P(Y)\n",
        "def logDist_Y(Y, hipY, param_1, param_2):\n",
        "  if hipY == 'uniforme':\n",
        "    logY = pm.logp(pm.Uniform.dist(lower=param_1, upper=param_2), Y)\n",
        "  elif hipY == 'normal':\n",
        "    logY = pm.logp(pm.Normal.dist(mu=param_1, sigma=param_2), Y)\n",
        "  elif hipY == 'gamma':\n",
        "    logY = pm.logp(pm.Gamma.dist(alpha=param_1, beta=1/param_2), Y)\n",
        "  elif hipY == 'beta':\n",
        "    logY = pm.logp(pm.Beta.dist(alpha=param_1, beta=param_2), Y)\n",
        "  else: raise ValueError(f\"Unknown hipY: {hipY}\")\n",
        "  return logY\n",
        "\n",
        "# Hipótesis sobre P(R|Y)\n",
        "def logDist_RmidY(R, Y, hipR, param_1, param_2):\n",
        "  if hipR == \"normal\":\n",
        "    dist = pm.Normal.dist(mu=param_1, sigma=param_2)\n",
        "  elif hipR == \"beta\":\n",
        "    dist = pm.Beta.dist(alpha=param_1, beta=param_2)\n",
        "  elif hipR == \"gamma\":\n",
        "    dist = pm.Gamma.dist(alpha=param_1, beta=1/param_2)\n",
        "  else:\n",
        "    raise ValueError(f\"Unknown hipR: {hipR}\")\n",
        "  p = pm.logp(dist, Y)\n",
        "  R_tensor = pt.as_tensor_variable(R)\n",
        "  prob = pt.exp(p)\n",
        "  prob = pt.clip(prob, 1e-9, 1 - 1e-9)\n",
        "  return pt.switch(pt.eq(R_tensor, 1), pt.log(prob), pt.log1p(-prob))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGcSU_k0wIaz"
      },
      "outputs": [],
      "source": [
        "def EstimaSeleccion(df, hipY, hipR, dicPriors, dicPosteriors=None, var='Y', seguimiento=0, df_seg=None, show=0):\n",
        "\n",
        "    dicPosteriors = {} if dicPosteriors is None else dicPosteriors\n",
        "\n",
        "    with pm.Model() as modelo:\n",
        "\n",
        "        theta = []\n",
        "        theta_dict = {}\n",
        "\n",
        "        for i, (nombre, prior) in enumerate(dicPriors.items()):\n",
        "            if isinstance(prior, (int, float, np.number)):\n",
        "                theta_i = prior\n",
        "            elif dicPosteriors and nombre in dicPosteriors:\n",
        "                muestras_aux = dicPosteriors[nombre].values.reshape(-1)\n",
        "                muestras_i = pm.math.constant(muestras_aux)\n",
        "                aux_i = pm.Categorical(f'{nombre}_aux', p=np.ones(len(muestras_aux)) / len(muestras_aux))\n",
        "                theta_i = pm.Deterministic(nombre, muestras_i[aux_i])\n",
        "            else:\n",
        "                theta_i = prior_theta(nombre, prior)\n",
        "\n",
        "            theta.append(theta_i)\n",
        "            theta_dict[nombre] = theta_i\n",
        "\n",
        "        if seguimiento == 0:\n",
        "            registro = df[var].values\n",
        "            R_val = 1\n",
        "            logY = logDist_Y(registro, hipY, theta[0], theta[1])\n",
        "            logRmidY = logDist_RmidY(R_val, registro, hipR, theta[2], theta[3])\n",
        "        else:\n",
        "            registro_obs = df[var].values\n",
        "            registro_aus = df_seg[var].values\n",
        "            registro_total = pd.concat([df[var], df_seg[var]], ignore_index=True).values\n",
        "\n",
        "            logY = logDist_Y(registro_total, hipY, theta[0], theta[1])\n",
        "            logRmidY = (\n",
        "    pm.math.sum(logDist_RmidY(1, registro_obs, hipR, theta[2], theta[3])) +\n",
        "    pm.math.sum(logDist_RmidY(0, registro_aus, hipR, theta[2], theta[3])))\n",
        "\n",
        "        # Se suma como Potential\n",
        "        pm.Potential(\"likelihood\", logY + logRmidY)\n",
        "\n",
        "        #Sampleo\n",
        "        muestras_posterior = pm.sample(init=\"adapt_diag\", progressbar=True, return_inferencedata=True, tune=1000, draws = 1000)\n",
        "\n",
        "    return muestras_posterior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J_mD40DnOTm"
      },
      "source": [
        "## Definición de hipótesis / priors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6PLBVPGnZQI"
      },
      "outputs": [],
      "source": [
        "def get_prior(row):\n",
        "    dist = row.prior_dist\n",
        "    p1 = None if pd.isna(row.param1) else float(row.param1)\n",
        "    p2 = None if pd.isna(row.param2) else float(row.param2)\n",
        "    if dist == \"const\":\n",
        "        return p1\n",
        "    if dist == \"flat\":\n",
        "        return parametros(\"flat\")\n",
        "    if p2 is None:\n",
        "        return parametros(dist, p1)\n",
        "    else:\n",
        "      return parametros(dist,p1, p2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUVfGoO0iLHb"
      },
      "outputs": [],
      "source": [
        "def get_hypothesis(sim, method):\n",
        "    modelo = sim[sim.method == method]\n",
        "    assumed_dists = []\n",
        "    chosen_priors = []\n",
        "    lims_list = []\n",
        "    for hid, hdf in modelo.groupby(\"hyp_id\"):\n",
        "        dist_1 = hdf.dist_1.iloc[0]\n",
        "        dist_2 = hdf.dist_2.iloc[0]\n",
        "        assumed_dists.append((dist_1, dist_2))\n",
        "\n",
        "        lim_inf = hdf.lim_inf.iloc[0]\n",
        "        lim_sup = hdf.lim_sup.iloc[0]\n",
        "        lims_list.append([lim_inf, lim_sup])\n",
        "\n",
        "        priors_for_h = []\n",
        "        for pid, pdf in hdf.groupby(\"prior_id\"):\n",
        "            priors = {'sim_id': pdf.sim_id.iloc[0]}\n",
        "            for _, row in pdf.iterrows():\n",
        "                priors[row.theta] = get_prior(row)\n",
        "            priors_for_h.append(priors)\n",
        "        chosen_priors.append(priors_for_h)\n",
        "    return assumed_dists, chosen_priors, lims_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvpGyquhDIpr"
      },
      "source": [
        "## Ejecución modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlmKkKdqldP5"
      },
      "source": [
        "### Modelo base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9aMpXIgUIgB"
      },
      "outputs": [],
      "source": [
        "def Estima_thetas(dir_sim, label, idx_iter=None):\n",
        "\n",
        "    modelos = []\n",
        "\n",
        "    hyp_path = pd.read_csv(dir_sim / f\"Hip_{label}.csv\")\n",
        "    assumed_dists_m, chosen_priors_m, lims_m = get_hypothesis(hyp_path, \"Mezcla\")\n",
        "    assumed_dists_s, chosen_priors_s, lims_s = get_hypothesis(hyp_path, \"Seleccion\")\n",
        "\n",
        "    datos_dir = dir_sim / f\"Datos_observados\"\n",
        "    datos_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if idx_iter is None:\n",
        "      thetas_dir = dir_sim / f\"Estimaciones_theta\"\n",
        "    else:\n",
        "      thetas_dir = dir_sim / f\"Ejecuciones/Estimaciones_theta\"\n",
        "    thetas_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ind_iter = f\"_{idx_iter+1}\" if idx_iter is not None else \"\"\n",
        "\n",
        "    for path in datos_dir.glob(\"*.csv\"):\n",
        "        if path.name.endswith(\"seg.csv\"):\n",
        "          continue\n",
        "\n",
        "        df = pd.read_csv(path)\n",
        "        name = path.stem\n",
        "\n",
        "        for ((hipYobs, hipYaus), priors_list, lims) in zip(assumed_dists_m, chosen_priors_m, lims_m):\n",
        "            for dicPriors in priors_list:\n",
        "\n",
        "                dicPriors_local = dicPriors.copy()\n",
        "                sim_id = dicPriors_local.pop(\"sim_id\")\n",
        "\n",
        "                tic = time.time()\n",
        "                muestras_posterior = EstimaMezcla(df, hipYobs, hipYaus, dicPriors_local)\n",
        "                tac = time.time()\n",
        "\n",
        "                posterior_df = az.extract(muestras_posterior, group=\"posterior\").to_dataframe()\n",
        "\n",
        "                theta_0 = posterior_df[\"theta_0\"].mean()\n",
        "                theta_1 = posterior_df[\"theta_1\"].mean()\n",
        "                theta_2 = dicPriors_local[\"theta_2\"]\n",
        "                theta_3 = dicPriors_local[\"theta_3\"]\n",
        "                lim_inf = lims[0]\n",
        "                lim_sup = lims[1]\n",
        "\n",
        "                modelo_local = {\"sim_id\": f'{name}_{sim_id}',\n",
        "                                \"method\": \"Mezcla\",\n",
        "                                \"P_R\": 0.5,\n",
        "                                \"dist_1\": hipYobs,\n",
        "                                \"dist_1_param_1\": theta_0,\n",
        "                                \"dist_1_param_2\": theta_1,\n",
        "                                \"dist_2\": hipYaus,\n",
        "                                \"dist_2_param_1\": theta_2,\n",
        "                                \"dist_2_param_2\": theta_3,\n",
        "                                \"lim_inf\": lim_inf,\n",
        "                                \"lim_sup\": lim_sup,\n",
        "                                \"time\": tac - tic}\n",
        "                modelos.append(modelo_local)\n",
        "\n",
        "        for ((dist_Y, dist_RmidY), priors_list, lims) in zip(assumed_dists_s, chosen_priors_s, lims_s):\n",
        "            for dicPriors in priors_list:\n",
        "\n",
        "                dicPriors_local = dicPriors.copy()\n",
        "                sim_id = dicPriors_local.pop(\"sim_id\")\n",
        "\n",
        "                tic = time.time()\n",
        "                muestras_posterior = EstimaSeleccion(df, dist_Y, dist_RmidY, dicPriors_local)\n",
        "                tac = time.time()\n",
        "\n",
        "                posterior_df = az.extract(muestras_posterior, group=\"posterior\").to_dataframe()\n",
        "\n",
        "                theta_0 = posterior_df[\"theta_0\"].mean()\n",
        "                theta_1 = posterior_df[\"theta_1\"].mean()\n",
        "                theta_2 = posterior_df[\"theta_2\"].mean()\n",
        "                theta_3 = posterior_df[\"theta_3\"].mean()\n",
        "                lim_inf = lims[0]\n",
        "                lim_sup = lims[1]\n",
        "\n",
        "                modelo_local = {\"sim_id\": f'{name}_{sim_id}',\n",
        "                                \"method\": \"Seleccion\",\n",
        "                                \"P_R\": 0.5,\n",
        "                                \"dist_1\": dist_Y,\n",
        "                                \"dist_1_param_1\": theta_0,\n",
        "                                \"dist_1_param_2\": theta_1,\n",
        "                                \"dist_2\": dist_RmidY,\n",
        "                                \"dist_2_param_1\": theta_2,\n",
        "                                \"dist_2_param_2\": theta_3,\n",
        "                                \"lim_inf\": lim_inf,\n",
        "                                \"lim_sup\": lim_sup,\n",
        "                                \"time\": tac - tic}\n",
        "                modelos.append(modelo_local)\n",
        "\n",
        "    modelos_df = pd.DataFrame(modelos)\n",
        "    modelos_df.to_csv(thetas_dir/f\"Estim_{label}{ind_iter}.csv\", index=False)\n",
        "\n",
        "    return modelos_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9FSgU6i8tGz"
      },
      "source": [
        "### Seguimiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMJL9pLi8r68"
      },
      "outputs": [],
      "source": [
        "def Estima_thetas_seguimiento(dir_sim, label, idx_iter=None, pct=0.15):\n",
        "\n",
        "    modelos = []\n",
        "\n",
        "    def get_theta_value(posterior_df, dicPriors_local, theta_name):\n",
        "        if theta_name in posterior_df.columns:\n",
        "            return posterior_df[theta_name].mean()\n",
        "\n",
        "        prior_value = dicPriors_local.get(theta_name)\n",
        "        if isinstance(prior_value, (int, float, np.number)):\n",
        "            return float(prior_value)\n",
        "        if isinstance(prior_value, dict) and \"param1\" in prior_value:\n",
        "            return float(prior_value[\"param1\"])\n",
        "\n",
        "        return np.nan\n",
        "\n",
        "    def normalize_pct(raw_pct, default_pct):\n",
        "        if raw_pct is None or raw_pct == \"\":\n",
        "            value = float(default_pct)\n",
        "        else:\n",
        "            value = float(raw_pct)\n",
        "            if value > 1:\n",
        "                value = value / 100\n",
        "        return f\"{value:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
        "\n",
        "    hyp_path = pd.read_csv(dir_sim / f\"Hip_{label}.csv\")\n",
        "    assumed_dists_m, chosen_priors_m, lims_m = get_hypothesis(hyp_path, \"Mezcla\")\n",
        "    assumed_dists_s, chosen_priors_s, lims_s = get_hypothesis(hyp_path, \"Seleccion\")\n",
        "\n",
        "    datos_dir = dir_sim / f\"Datos_observados\"\n",
        "\n",
        "    if idx_iter is None:\n",
        "      thetas_dir = dir_sim / f\"Estimaciones_theta_seg\"\n",
        "    else:\n",
        "      thetas_dir = dir_sim / f\"Ejecuciones/Estimaciones_theta_seg\"\n",
        "    thetas_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ind_iter = f\"_{idx_iter+1}\" if idx_iter is not None else \"\"\n",
        "\n",
        "    for path in datos_dir.glob(\"*.csv\"):\n",
        "        if path.name.endswith(\"seg.csv\"):\n",
        "          continue\n",
        "\n",
        "        df = pd.read_csv(path)\n",
        "\n",
        "        name = path.stem\n",
        "        for seg_path in datos_dir.glob(f\"*{name}_*seg.csv\"):\n",
        "\n",
        "          pct_match = re.search(r\"_(.*?)seg$\", Path(seg_path).stem)\n",
        "          pct_raw = pct_match.group(1) if pct_match else \"\"\n",
        "          pct_str = normalize_pct(pct_raw, pct)\n",
        "          df_seg = pd.read_csv(seg_path)\n",
        "\n",
        "          for ((hipYobs, hipYaus), priors_list, lims) in zip(assumed_dists_m, chosen_priors_m, lims_m):\n",
        "              for dicPriors in priors_list:\n",
        "\n",
        "                  dicPriors_local = dicPriors.copy()\n",
        "                  sim_id = dicPriors_local.pop(\"sim_id\")\n",
        "\n",
        "                  tic = time.time()\n",
        "                  muestras_posterior = EstimaMezcla(df, hipYobs, hipYaus, dicPriors_local, seguimiento=1, df_seg=df_seg)\n",
        "                  tac = time.time()\n",
        "\n",
        "                  posterior_df = az.extract(muestras_posterior, group=\"posterior\").to_dataframe()\n",
        "\n",
        "                  theta_0 = get_theta_value(posterior_df, dicPriors_local, \"theta_0\")\n",
        "                  theta_1 = get_theta_value(posterior_df, dicPriors_local, \"theta_1\")\n",
        "                  theta_2 = get_theta_value(posterior_df, dicPriors_local, \"theta_2\")\n",
        "                  theta_3 = get_theta_value(posterior_df, dicPriors_local, \"theta_3\")\n",
        "                  lim_inf = lims[0]\n",
        "                  lim_sup = lims[1]\n",
        "\n",
        "                  modelo_local = {\"sim_id\": f'{name}_{sim_id}_{pct_str}_seg',\n",
        "                                  \"method\": \"Mezcla\",\n",
        "                                  \"P_R\": 0.5,\n",
        "                                  \"dist_1\": hipYobs,\n",
        "                                  \"dist_1_param_1\": theta_0,\n",
        "                                  \"dist_1_param_2\": theta_1,\n",
        "                                  \"dist_2\": hipYaus,\n",
        "                                  \"dist_2_param_1\": theta_2,\n",
        "                                  \"dist_2_param_2\": theta_3,\n",
        "                                  \"lim_inf\": lim_inf,\n",
        "                                  \"lim_sup\": lim_sup,\n",
        "                                  \"time\": tac - tic}\n",
        "\n",
        "                  modelos.append(modelo_local)\n",
        "\n",
        "          for ((dist_Y, dist_RmidY), priors_list, lims) in zip(assumed_dists_s, chosen_priors_s, lims_s):\n",
        "              for dicPriors in priors_list:\n",
        "\n",
        "                  dicPriors_local = dicPriors.copy()\n",
        "                  sim_id = dicPriors_local.pop(\"sim_id\")\n",
        "\n",
        "                  tic = time.time()\n",
        "                  muestras_posterior = EstimaSeleccion(df, dist_Y, dist_RmidY, dicPriors_local, seguimiento=1, df_seg=df_seg)\n",
        "                  tac = time.time()\n",
        "\n",
        "                  posterior_df = az.extract(muestras_posterior, group=\"posterior\").to_dataframe()\n",
        "\n",
        "                  theta_0 = get_theta_value(posterior_df, dicPriors_local, \"theta_0\")\n",
        "                  theta_1 = get_theta_value(posterior_df, dicPriors_local, \"theta_1\")\n",
        "                  theta_2 = get_theta_value(posterior_df, dicPriors_local, \"theta_2\")\n",
        "                  theta_3 = get_theta_value(posterior_df, dicPriors_local, \"theta_3\")\n",
        "                  lim_inf = lims[0]\n",
        "                  lim_sup = lims[1]\n",
        "\n",
        "                  modelo_local = {\"sim_id\": f'{name}_{sim_id}_{pct_str}_seg',\n",
        "                                  \"method\": \"Seleccion\",\n",
        "                                  \"P_R\": 0.5,\n",
        "                                  \"dist_1\": dist_Y,\n",
        "                                  \"dist_1_param_1\": theta_0,\n",
        "                                  \"dist_1_param_2\": theta_1,\n",
        "                                  \"dist_2\": dist_RmidY,\n",
        "                                  \"dist_2_param_1\": theta_2,\n",
        "                                  \"dist_2_param_2\": theta_3,\n",
        "                                  \"lim_inf\": lim_inf,\n",
        "                                  \"lim_sup\": lim_sup,\n",
        "                                  \"time\": tac - tic}\n",
        "                  modelos.append(modelo_local)\n",
        "\n",
        "    modelos_df = pd.DataFrame(modelos)\n",
        "    modelos_df.to_csv(thetas_dir/f\"Estim_{label}_seg{ind_iter}.csv\", index=False)\n",
        "\n",
        "    return modelos_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge0XKXdmliK1"
      },
      "source": [
        "### Actualización priors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5wSsfUelqJj"
      },
      "outputs": [],
      "source": [
        "def Estima_thetas_updatepriors(dir_sim, label, n_iter=1, idx_iter=None, seguimiento=0, df_seg=None):\n",
        "\n",
        "    modelos = []\n",
        "\n",
        "    def get_theta_value(posterior_df, dicPriors_local, theta_name):\n",
        "        if theta_name in posterior_df.columns:\n",
        "            return posterior_df[theta_name].mean()\n",
        "\n",
        "        prior_value = dicPriors_local.get(theta_name)\n",
        "        if isinstance(prior_value, (int, float, np.number)):\n",
        "            return float(prior_value)\n",
        "        if isinstance(prior_value, dict) and \"param1\" in prior_value:\n",
        "            return float(prior_value[\"param1\"])\n",
        "\n",
        "        return np.nan\n",
        "\n",
        "    hyp_path = pd.read_csv(dir_sim / f\"Hip_{label}.csv\")\n",
        "    assumed_dists_m, chosen_priors_m, lims_m = get_hypothesis(hyp_path, \"Mezcla\")\n",
        "    assumed_dists_s, chosen_priors_s, lims_s = get_hypothesis(hyp_path, \"Seleccion\")\n",
        "\n",
        "    datos_dir = dir_sim / f\"Datos_observados\"\n",
        "    datos_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ind_seg = \"_seg\" if seguimiento == 1 else \"\"\n",
        "\n",
        "    if idx_iter is None:\n",
        "      thetas_dir = dir_sim / f\"Estimaciones_theta_updatepriors{ind_seg}\"\n",
        "    else:\n",
        "      thetas_dir = dir_sim / f\"Ejecuciones/Estimaciones_theta_updatepriors{ind_seg}\"\n",
        "    thetas_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ind_iter = f\"_{idx_iter+1}\" if idx_iter is not None else \"\"\n",
        "\n",
        "    for path in datos_dir.glob(\"*.csv\"):\n",
        "        if path.name.endswith(\"seg.csv\"):\n",
        "          continue\n",
        "\n",
        "        df = pd.read_csv(path)\n",
        "        name = path.stem\n",
        "\n",
        "        if seguimiento == 1:\n",
        "          seg_candidates = list(datos_dir.glob(f\"{name}_*seg.csv\"))\n",
        "          if not seg_candidates:\n",
        "            raise FileNotFoundError(f\"No se encontro seguimiento para {name} en {datos_dir}\")\n",
        "          df_seg_local = pd.read_csv(seg_candidates[0])\n",
        "        else:\n",
        "          df_seg_local = df_seg\n",
        "\n",
        "        for ((hipYobs, hipYaus), priors_list, lims) in zip(assumed_dists_m, chosen_priors_m, lims_m):\n",
        "            for dicPriors in priors_list:\n",
        "\n",
        "                dicPriors_local = dicPriors.copy()\n",
        "                sim_id = dicPriors_local.pop(\"sim_id\")\n",
        "\n",
        "                muestras_posterior = None\n",
        "\n",
        "                for iter_idx in range(n_iter):\n",
        "                    tic = time.time()\n",
        "                    if iter_idx == 0:\n",
        "                        muestras_posterior = EstimaMezcla(df, hipYobs, hipYaus, dicPriors_local, seguimiento=seguimiento, df_seg=df_seg_local)\n",
        "                    else:\n",
        "                        muestras_posterior = EstimaMezcla(df, hipYobs, hipYaus, dicPriors_local, muestras_posterior, seguimiento=seguimiento, df_seg=df_seg_local)\n",
        "                    tac = time.time()\n",
        "\n",
        "                    posterior_df = az.extract(muestras_posterior, group=\"posterior\").to_dataframe()\n",
        "\n",
        "                    theta_0 = get_theta_value(posterior_df, dicPriors_local, \"theta_0\")\n",
        "                    theta_1 = get_theta_value(posterior_df, dicPriors_local, \"theta_1\")\n",
        "                    theta_2 = get_theta_value(posterior_df, dicPriors_local, \"theta_2\")\n",
        "                    theta_3 = get_theta_value(posterior_df, dicPriors_local, \"theta_3\")\n",
        "                    lim_inf = lims[0]\n",
        "                    lim_sup = lims[1]\n",
        "\n",
        "                    modelo_local = {\"sim_id\": f\"{name}_{sim_id}_{iter_idx}\",\n",
        "                                    \"method\": \"Mezcla\",\n",
        "                                    \"P_R\": 0.5,\n",
        "                                    \"dist_1\": hipYobs,\n",
        "                                    \"dist_1_param_1\": theta_0,\n",
        "                                    \"dist_1_param_2\": theta_1,\n",
        "                                    \"dist_2\": hipYaus,\n",
        "                                    \"dist_2_param_1\": theta_2,\n",
        "                                    \"dist_2_param_2\": theta_3,\n",
        "                                    \"lim_inf\": lim_inf,\n",
        "                                    \"lim_sup\": lim_sup,\n",
        "                                    \"time\": tac - tic}\n",
        "\n",
        "                    modelos.append(modelo_local)\n",
        "\n",
        "        for ((dist_Y, dist_RmidY), priors_list, lims) in zip(assumed_dists_s, chosen_priors_s, lims_s):\n",
        "            for dicPriors in priors_list:\n",
        "\n",
        "                dicPriors_local = dicPriors.copy()\n",
        "                sim_id = dicPriors_local.pop(\"sim_id\")\n",
        "\n",
        "                muestras_posterior = None\n",
        "                for iter_idx in range(n_iter):\n",
        "\n",
        "                    tic = time.time()\n",
        "                    if iter_idx == 0:\n",
        "                        muestras_posterior = EstimaSeleccion(df, dist_Y, dist_RmidY, dicPriors_local, seguimiento=seguimiento, df_seg=df_seg_local)\n",
        "                    else:\n",
        "                        muestras_posterior = EstimaSeleccion(df, dist_Y, dist_RmidY, dicPriors_local, muestras_posterior, seguimiento=seguimiento, df_seg=df_seg_local)\n",
        "                    tac = time.time()\n",
        "\n",
        "                    posterior_df = az.extract(muestras_posterior, group=\"posterior\").to_dataframe()\n",
        "\n",
        "                    theta_0 = get_theta_value(posterior_df, dicPriors_local, \"theta_0\")\n",
        "                    theta_1 = get_theta_value(posterior_df, dicPriors_local, \"theta_1\")\n",
        "                    theta_2 = get_theta_value(posterior_df, dicPriors_local, \"theta_2\")\n",
        "                    theta_3 = get_theta_value(posterior_df, dicPriors_local, \"theta_3\")\n",
        "                    lim_inf = lims[0]\n",
        "                    lim_sup = lims[1]\n",
        "\n",
        "                    modelo_local = {\"sim_id\": f\"{name}_{sim_id}_{iter_idx}\",\n",
        "                                    \"method\": \"Seleccion\",\n",
        "                                    \"P_R\": 0.5,\n",
        "                                    \"dist_1\": dist_Y,\n",
        "                                    \"dist_1_param_1\": theta_0,\n",
        "                                    \"dist_1_param_2\": theta_1,\n",
        "                                    \"dist_2\": dist_RmidY,\n",
        "                                    \"dist_2_param_1\": theta_2,\n",
        "                                    \"dist_2_param_2\": theta_3,\n",
        "                                    \"lim_inf\": lim_inf,\n",
        "                                    \"lim_sup\": lim_sup,\n",
        "                                    \"time\": tac - tic}\n",
        "                    modelos.append(modelo_local)\n",
        "\n",
        "    modelos_df = pd.DataFrame(modelos)\n",
        "    modelos_df.to_csv(thetas_dir / f\"Estim_{label}{ind_iter}.csv\", index=False)\n",
        "\n",
        "    return modelos_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJPu8iJfCjbO"
      },
      "source": [
        "### Sampleo Gibbs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mNPYCDpjRy_"
      },
      "outputs": [],
      "source": [
        "def genera_datos_gibbs(input_path=None, input_dict=None, df=None,\n",
        "                       pct=0.15, n_muestras=1000, P_R=0.5):\n",
        "\n",
        "    if df is None:\n",
        "        if input_path is None:\n",
        "            df = pd.DataFrame([input_dict])\n",
        "        else:\n",
        "            df = pd.read_csv(input_path)\n",
        "\n",
        "    if input_path is not None:\n",
        "        input_path = Path(input_path)\n",
        "        output_dir = input_path.parent / 'Datos_generados'\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        observed_dir = input_path.parent / 'Datos_observados'\n",
        "        observed_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "\n",
        "        sim_id = row['sim_id']\n",
        "        method = row['method'].lower()\n",
        "\n",
        "        dist_1 = parametros(row['dist_1'], row['dist_1_param_1'], row['dist_1_param_2'],row['lim_inf'],row['lim_sup'])\n",
        "        dist_2 = parametros(row['dist_2'], row['dist_2_param_1'], row['dist_2_param_2'],row['lim_inf'],row['lim_sup'])\n",
        "\n",
        "        if method == 'mezcla':\n",
        "            P_R_row = row['P_R']\n",
        "            YR = datos_mezcla(P_R_row, 'Y', dist_1, dist_2, n_muestras=n_muestras*10)\n",
        "\n",
        "        elif method == 'seleccion':\n",
        "            YR = datos_seleccion(dist_1, dist_2, n_muestras=n_muestras*10)\n",
        "\n",
        "        if P_R is not None:\n",
        "            assert 0 <= P_R <= 1, \"P_R debe estar en el intervalo [0,1]\"\n",
        "            idx0 = YR.index[YR[\"R\"] == 0]\n",
        "            idx1 = YR.index[YR[\"R\"] == 1]\n",
        "\n",
        "            idx_aus_sampled = np.random.choice(idx0, size=int(n_muestras*(1-P_R)), replace=True)\n",
        "            idx_obs_sampled = np.random.choice(idx1, size=int(n_muestras*P_R), replace=True)\n",
        "\n",
        "            df_obs = YR.loc[idx_obs_sampled]\n",
        "            df_aus = YR.loc[idx_aus_sampled]\n",
        "\n",
        "            YR = pd.concat([df_obs, df_aus], ignore_index=True)\n",
        "\n",
        "        if input_path is None:\n",
        "            return YR\n",
        "\n",
        "        for col, value in row.items():\n",
        "            YR[col] = value\n",
        "\n",
        "        output_path = output_dir / f\"{sim_id}.csv\"\n",
        "        YR.to_csv(output_path, index=False)\n",
        "\n",
        "        YR_seg = YR.copy()\n",
        "        idx_R = YR_seg.columns.get_loc(\"R\")\n",
        "        YR_seg.insert(idx_R + 1, \"S\", YR_seg[\"R\"] )\n",
        "\n",
        "        idx_aus = YR_seg.index[YR_seg[\"S\"] == 0]\n",
        "        len_aus = len(idx_aus)\n",
        "        idx_flip = np.random.choice(idx_aus, size=int(pct * len_aus), replace=False)\n",
        "        YR_seg.loc[idx_flip, \"S\"] = 1\n",
        "\n",
        "        seguimiento_path = output_dir / f\"{sim_id}_seg.csv\"\n",
        "        YR_seg.to_csv(seguimiento_path, index=False)\n",
        "\n",
        "        YR_obs = YR.loc[YR[\"R\"] == 1, \"Y\"]\n",
        "        YR_obs.to_csv(observed_dir / f\"{sim_id}.csv\", index=False)\n",
        "\n",
        "        YR_obs_seg = YR_seg.loc[(YR_seg[\"R\"] == 0) & (YR_seg[\"S\"] == 1), \"Y\"]\n",
        "        YR_obs_seg.to_csv(observed_dir / f\"{sim_id}_seg.csv\", index=False)\n",
        "\n",
        "    return YR[['Y', 'R']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELQ1o6PliVfl"
      },
      "outputs": [],
      "source": [
        "def genera_seguimiento(YR=None, data_dir=None, pct=0.15, n_muestras=1000):\n",
        "\n",
        "    if YR is None:\n",
        "      data_dir = Path(data_dir)\n",
        "      observed_dir = data_dir.parent / 'Datos_observados'\n",
        "      observed_dir.mkdir(parents=True, exist_ok=True)\n",
        "      for path in data_dir.glob(\"*.csv\"):\n",
        "        if path.name.endswith(\"seg.csv\"):\n",
        "          continue\n",
        "        YR = pd.read_csv(path)\n",
        "\n",
        "    YR_seg = YR.copy()\n",
        "\n",
        "    idx_R = YR_seg.columns.get_loc(\"R\")\n",
        "    YR_seg.insert((idx_R) + 1, \"S\", YR_seg[\"R\"] )\n",
        "\n",
        "    idx_aus = YR_seg.index[YR_seg[\"S\"] == 0]\n",
        "    len_aus = len(idx_aus)\n",
        "\n",
        "    idx_flip = np.random.choice(idx_aus, size=int(pct*len_aus), replace=False)\n",
        "    YR_seg.loc[idx_flip, \"S\"] = 1\n",
        "\n",
        "    YR_obs = YR.loc[YR[\"R\"] == 1, \"Y\"]\n",
        "    YR_obs_seg = YR_seg.loc[(YR_seg[\"R\"] == 0) & (YR_seg[\"S\"] == 1), \"Y\"]\n",
        "\n",
        "    if data_dir is not None:\n",
        "      sim_id = YR_seg['sim_id'].iloc[0]\n",
        "      seguimiento_path = path.parent / f\"{sim_id}_{pct}seg.csv\"\n",
        "      if pct > 0:\n",
        "        YR_seg.to_csv(seguimiento_path, index=False)\n",
        "      YR_obs.to_csv(observed_dir / f\"{sim_id}.csv\", index=False)\n",
        "      if pct > 0:\n",
        "        YR_obs_seg.to_csv(observed_dir / f\"{sim_id}_{pct}seg.csv\", index=False)\n",
        "\n",
        "    return YR_obs_seg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtl_C6qXEZTf"
      },
      "outputs": [],
      "source": [
        "def Estima_thetas_gibbs(dir_sim, label, n_iter=1, idx_iter=None, P_R=0.5, seguimiento=0, df_seg=None):\n",
        "\n",
        "    modelos = []\n",
        "\n",
        "    label_name = label\n",
        "    hyp_path = pd.read_csv(dir_sim / f\"Hip_{label_name}.csv\")\n",
        "    orig_dir = dir_sim / f\"Datos_observados\"\n",
        "    assumed_dists_m, chosen_priors_m, lims_m = get_hypothesis(hyp_path, \"Mezcla\")\n",
        "    assumed_dists_s, chosen_priors_s, lims_s = get_hypothesis(hyp_path, \"Seleccion\")\n",
        "\n",
        "    ind_seg = f\"_seg\" if seguimiento==1 else \"\"\n",
        "    label = \"*.csv\"\n",
        "\n",
        "    if idx_iter is None:\n",
        "      gibbs_dir = dir_sim / f\"Estimaciones_theta_gibbs{ind_seg}\"\n",
        "    else:\n",
        "      gibbs_dir = dir_sim / f\"Ejecuciones/Estimaciones_theta_gibbs{ind_seg}\"\n",
        "    gibbs_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ind_iter = f\"_{idx_iter+1}\" if idx_iter is not None else \"\"\n",
        "\n",
        "    inter_dir = gibbs_dir / f\"Estimaciones_intermedias{ind_seg}\"\n",
        "    inter_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    datos_dir = gibbs_dir / f\"Datos_generados_gibbs{ind_seg}\"\n",
        "    datos_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for path in orig_dir.glob(label):\n",
        "\n",
        "        if path.name.endswith(\"seg.csv\"):\n",
        "            continue\n",
        "\n",
        "        df = pd.read_csv(path)\n",
        "        name = path.stem\n",
        "\n",
        "        if seguimiento == 1:\n",
        "            seg_candidates = list(orig_dir.glob(f\"{name}_*seg.csv\"))\n",
        "            if not seg_candidates:\n",
        "                raise FileNotFoundError(f\"No se encontro seguimiento para {name} en {orig_dir}\")\n",
        "            df_seg = pd.read_csv(seg_candidates[0])\n",
        "        else:\n",
        "            df_seg = None\n",
        "\n",
        "        allowed_methods = None\n",
        "        allowed_model_tag = None\n",
        "        if name.startswith(\"Pm\"):\n",
        "            allowed_methods = {\"mezcla\"}\n",
        "            allowed_model_tag = \"M00\"\n",
        "        elif name.startswith(\"Ps\"):\n",
        "            allowed_methods = {\"selec\"}\n",
        "            allowed_model_tag = \"S00\"\n",
        "\n",
        "        method = \"mezcla\"\n",
        "        if allowed_methods is None or method in allowed_methods:\n",
        "            local_df = df.copy()\n",
        "            for ((hipYobs, hipYaus), priors_list, lims) in zip(assumed_dists_m, chosen_priors_m, lims_m):\n",
        "                for dicPriors in priors_list:\n",
        "\n",
        "                    dicPriors_local = dicPriors.copy()\n",
        "                    sim_id = dicPriors_local.pop(\"sim_id\")\n",
        "                    if allowed_model_tag and allowed_model_tag not in str(sim_id):\n",
        "                        continue\n",
        "\n",
        "                    muestras_posterior = None\n",
        "                    modelo_bucle = []\n",
        "\n",
        "                    for idx in range(n_iter):\n",
        "                        tic = time.time()\n",
        "                        if idx == 0:\n",
        "                            muestras_posterior = EstimaMezcla(local_df, hipYobs, hipYaus, dicPriors_local, seguimiento=seguimiento, df_seg=df_seg)\n",
        "                        else:\n",
        "                            if (seguimiento == 1) and (not local_obs.empty) and (not local_aus.empty):\n",
        "                                muestras_posterior = EstimaMezcla(local_obs, hipYobs, hipYaus, dicPriors_local, muestras_posterior, seguimiento=1, df_seg=local_aus)\n",
        "                            else:\n",
        "                                muestras_posterior = EstimaMezcla(local_df, hipYobs, hipYaus, dicPriors_local, muestras_posterior, seguimiento=0)\n",
        "                        tac = time.time()\n",
        "\n",
        "                        posterior_df = az.extract(muestras_posterior, group=\"posterior\").to_dataframe()\n",
        "\n",
        "                        theta_0 = posterior_df[\"theta_0\"].mean()\n",
        "                        theta_1 = posterior_df[\"theta_1\"].mean()\n",
        "                        theta_2 = dicPriors_local[\"theta_2\"]\n",
        "                        theta_3 = dicPriors_local[\"theta_3\"]\n",
        "                        lim_inf = lims[0]\n",
        "                        lim_sup = lims[1]\n",
        "\n",
        "                        modelo_local = {\"sim_id\": f\"{name}_{sim_id}_gibbs_{idx}\",\n",
        "                                        \"method\": \"Mezcla\",\n",
        "                                        \"P_R\": P_R,\n",
        "                                        \"dist_1\": hipYobs,\n",
        "                                        \"dist_1_param_1\": theta_0,\n",
        "                                        \"dist_1_param_2\": theta_1,\n",
        "                                        \"dist_2\": hipYaus,\n",
        "                                        \"dist_2_param_1\": theta_2,\n",
        "                                        \"dist_2_param_2\": theta_3,\n",
        "                                        \"lim_inf\": lim_inf,\n",
        "                                        \"lim_sup\": lim_sup,\n",
        "                                        \"time\": tac-tic}\n",
        "\n",
        "                        modelo_bucle.append(modelo_local)\n",
        "                        local_df = genera_datos_gibbs(input_dict=modelo_local, P_R=P_R)\n",
        "                        local_obs = local_df.loc[local_df[\"R\"] == 1,['Y']]\n",
        "                        local_aus = genera_seguimiento(YR=local_df, pct=1, n_muestras=1000).to_frame()\n",
        "\n",
        "                        local_obs.to_csv(datos_dir / f'{name}_{sim_id}_gibbs{ind_seg}{ind_iter}_obs_{idx}.csv', index=False)\n",
        "                        local_aus.to_csv(datos_dir / f'{name}_{sim_id}_gibbs{ind_seg}{ind_iter}_aus_{idx}.csv', index=False)\n",
        "\n",
        "                    modelo_bucle_df = pd.DataFrame(modelo_bucle)\n",
        "                    modelo_bucle_df.to_csv(inter_dir / f'{name}_{sim_id}{ind_seg}{ind_iter}.csv', index=False)\n",
        "\n",
        "                    modelos.append(modelo_local)\n",
        "\n",
        "\n",
        "        method = \"selec\"\n",
        "        if allowed_methods is None or method in allowed_methods:\n",
        "            local_df = df.copy()\n",
        "            for ((dist_Y, dist_RmidY), priors_list, lims) in zip(assumed_dists_s, chosen_priors_s, lims_s):\n",
        "                for dicPriors in priors_list:\n",
        "\n",
        "                    dicPriors_local = dicPriors.copy()\n",
        "                    sim_id = dicPriors_local.pop(\"sim_id\")\n",
        "                    if allowed_model_tag and allowed_model_tag not in str(sim_id):\n",
        "                        continue\n",
        "\n",
        "                    muestras_posterior = None\n",
        "                    modelo_bucle = []\n",
        "\n",
        "                    for idx in range(n_iter):\n",
        "\n",
        "                        tic = time.time()\n",
        "                        if idx == 0:\n",
        "                            muestras_posterior = EstimaSeleccion(local_df, dist_Y, dist_RmidY, dicPriors_local, seguimiento=seguimiento, df_seg=df_seg)\n",
        "                        else:\n",
        "                            if (seguimiento == 1) and (not local_obs.empty) and (not local_aus.empty):\n",
        "                                muestras_posterior = EstimaSeleccion(local_obs, dist_Y, dist_RmidY, dicPriors_local, muestras_posterior, seguimiento=1, df_seg=local_aus)\n",
        "                            else:\n",
        "                                muestras_posterior = EstimaSeleccion(local_df, dist_Y, dist_RmidY, dicPriors_local, muestras_posterior, seguimiento=0)\n",
        "                        tac = time.time()\n",
        "\n",
        "                        posterior_df = az.extract(muestras_posterior, group=\"posterior\").to_dataframe()\n",
        "\n",
        "                        theta_0 = posterior_df[\"theta_0\"].mean()\n",
        "                        theta_1 = posterior_df[\"theta_1\"].mean()\n",
        "                        theta_2 = posterior_df[\"theta_2\"].mean()\n",
        "                        theta_3 = posterior_df[\"theta_3\"].mean()\n",
        "                        lim_inf = lims[0]\n",
        "                        lim_sup = lims[1]\n",
        "\n",
        "                        modelo_local = {\"sim_id\": f\"{name}_{sim_id}_gibbs_{idx}\",\n",
        "                                      \"method\": \"Seleccion\",\n",
        "                                      \"P_R\": P_R,\n",
        "                                      \"dist_1\": dist_Y,\n",
        "                                      \"dist_1_param_1\": theta_0,\n",
        "                                      \"dist_1_param_2\": theta_1,\n",
        "                                      \"dist_2\": dist_RmidY,\n",
        "                                      \"dist_2_param_1\": theta_2,\n",
        "                                      \"dist_2_param_2\": theta_3,\n",
        "                                      \"lim_inf\": lim_inf,\n",
        "                                      \"lim_sup\": lim_sup,\n",
        "                                      \"time\": tac-tic}\n",
        "                        modelo_bucle.append(modelo_local)\n",
        "                        local_df = genera_datos_gibbs(input_dict=modelo_local, P_R=P_R)\n",
        "                        local_obs = local_df.loc[local_df[\"R\"] == 1,['Y']]\n",
        "                        local_aus = genera_seguimiento(YR=local_df, pct=1, n_muestras=1000).to_frame()\n",
        "\n",
        "                        local_obs.to_csv(datos_dir / f'{name}_{sim_id}_gibbs{ind_seg}{ind_iter}_obs_{idx}.csv', index=False)\n",
        "                        local_aus.to_csv(datos_dir / f'{name}_{sim_id}_gibbs{ind_seg}{ind_iter}_aus_{idx}.csv', index=False)\n",
        "\n",
        "                    modelo_bucle_df = pd.DataFrame(modelo_bucle)\n",
        "                    modelo_bucle_df.to_csv(inter_dir / f'{name}_{sim_id}{ind_seg}{ind_iter}.csv', index=False)\n",
        "\n",
        "                    modelos.append(modelo_local)\n",
        "\n",
        "    modelos_df = pd.DataFrame(modelos)\n",
        "    if modelos_df.empty:\n",
        "        raise ValueError(\"No se generaron modelos Gibbs; revisa filtros de metodo y sim_id.\")\n",
        "\n",
        "    modelos_df.to_csv(gibbs_dir / f\"Estim_{label_name}_gibbs_{n_iter}_iteraciones{ind_iter}.csv\", index=False)\n",
        "\n",
        "    return modelos_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBGrv-jeygth"
      },
      "source": [
        "## Iterativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oFgv43mNJto"
      },
      "outputs": [],
      "source": [
        "def resultados_to_csv(resultados, out_path, copy_fields, mean_fields):\n",
        "\n",
        "    agg_estruct = {}\n",
        "    for f in mean_fields:\n",
        "        agg_estruct[f] = (f, \"mean\")\n",
        "    for f in copy_fields:\n",
        "        agg_estruct[f] = (f, \"first\")\n",
        "\n",
        "    df_resumen = pd.concat(resultados, ignore_index=True)\n",
        "    df_final = (df_resumen.groupby(\"sim_id\", as_index=False).agg(**agg_estruct))\n",
        "    df_final = df_final[[\"sim_id\"] + copy_fields + mean_fields]\n",
        "    df_final.to_csv(out_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M9AgV0u-c2F"
      },
      "outputs": [],
      "source": [
        "def Estima_iterativo(dir, label, n_ejecuciones, n_iteraciones, base=1, seguimiento=1, updatepriors=1, gibbs=1, seg_updatepriors=1, seg_gibbs=1, P_R=0, pct=0.15):\n",
        "\n",
        "  dir_sim = Path(dir) / f\"Simulaciones_{label}\"\n",
        "  dir_sim.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  dir_iter = dir_sim / f\"Ejecuciones\"\n",
        "  dir_iter.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  resumen = []\n",
        "\n",
        "  mean_fields = [\"dist_1_param_1\",\"dist_1_param_2\",\"dist_2_param_1\",\"dist_2_param_2\",\"lim_inf\",\"lim_sup\",\"time\"]\n",
        "  copy_fields = [\"method\",\"P_R\",\"dist_1\",\"dist_2\"]\n",
        "\n",
        "  if base ==1:\n",
        "    for i in range(n_ejecuciones):\n",
        "      print(f'Estimando thetas - Ejecución {i+1}')\n",
        "      resultados = Estima_thetas(dir_sim, label, idx_iter=i)\n",
        "      resumen.append(resultados)\n",
        "    resultados_to_csv(resumen, dir_iter / f'Resumen_{n_ejecuciones}_ejecuciones.csv', copy_fields, mean_fields)\n",
        "    resumen = []\n",
        "\n",
        "  if seguimiento == 1:\n",
        "    for i in range(n_ejecuciones):\n",
        "      print(f'Estimando thetas con seguimiento - Ejecución {i+1}')\n",
        "      resultados = Estima_thetas_seguimiento(dir_sim, label, idx_iter=i, pct=pct)\n",
        "      resumen.append(resultados)\n",
        "    resultados_to_csv(resumen, dir_iter / f'Resumen_{n_ejecuciones}_ejecuciones_seguimiento.csv', copy_fields, mean_fields)\n",
        "    resumen = []\n",
        "\n",
        "  if updatepriors == 1:\n",
        "    for i in range(n_ejecuciones):\n",
        "      print(f'Estimando thetas con updatepriors - Ejecución {i+1}')\n",
        "      resultados = Estima_thetas_updatepriors(dir_sim, label, n_iter=n_iteraciones, idx_iter=i)\n",
        "      resumen.append(resultados)\n",
        "    resultados_to_csv(resumen, dir_iter / f'Resumen_{n_ejecuciones}_ejecuciones_updatepriors.csv', copy_fields, mean_fields)\n",
        "    resumen = []\n",
        "  if seg_updatepriors==1:\n",
        "      for i in range(n_ejecuciones):\n",
        "        print(f'Estimando thetas con updatepriors y datos de seguimiento - Ejecución {i+1}')\n",
        "        resultados = Estima_thetas_updatepriors(dir_sim, label, n_iter=n_iteraciones, idx_iter=i, seguimiento=1)\n",
        "        resumen.append(resultados)\n",
        "      resultados_to_csv(resumen, dir_iter / f'Resumen_{n_ejecuciones}_ejecuciones_updatepriors_seg.csv', copy_fields, mean_fields)\n",
        "      resumen = []\n",
        "\n",
        "  if gibbs == 1:\n",
        "    for i in range (n_ejecuciones):\n",
        "      print(f'Estimando thetas con gibbs - Ejecución {i+1}')\n",
        "      resultados = Estima_thetas_gibbs(dir_sim, label, n_iter=n_iteraciones, idx_iter=i, P_R=P_R)\n",
        "      resumen.append(resultados)\n",
        "    resultados_to_csv(resumen, dir_iter / f'Resumen_{n_ejecuciones}_ejecuciones_gibbs.csv', copy_fields, mean_fields)\n",
        "    resumen = []\n",
        "  if seg_gibbs==1:\n",
        "      for i in range (n_ejecuciones):\n",
        "        print(f'Estimando thetas con gibbs y datos de seguimiento - Ejecución {i+1}')\n",
        "        resultados = Estima_thetas_gibbs(dir_sim, label, n_iter=n_iteraciones, seguimiento=1, idx_iter=i, P_R=P_R)\n",
        "        resumen.append(resultados)\n",
        "      resultados_to_csv(resumen, dir_iter / f'Resumen_{n_ejecuciones}_ejecuciones_gibbs_seg.csv', copy_fields, mean_fields)\n",
        "      resumen = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWoR6Qa1DlwC"
      },
      "source": [
        "# Análisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTdUzYEBjIaZ"
      },
      "outputs": [],
      "source": [
        "def tabla_0(df_model, dicGen, row):\n",
        "  df_thetas = df_model.loc[df_model[\"model_method\"] == df_model[\"gen_method\"]]\n",
        "  if df_thetas.empty:\n",
        "      return None\n",
        "\n",
        "  orig_method = df_thetas[\"gen_data\"].astype(str).iloc[0]\n",
        "\n",
        "  dicData = dicGen[orig_method]\n",
        "\n",
        "  tabla0 = pd.DataFrame({'Dataset':orig_method, 'model':df_thetas['ID_modelo'] ,'priors': df_thetas['ID_prior'], 't_ejecucion':df_thetas['time']})\n",
        "\n",
        "  theta_0 = dicData['dist_1_param_1']\n",
        "  theta_1 = dicData['dist_1_param_2']\n",
        "\n",
        "  err_abs_theta_0 = (theta_0 - df_thetas[\"dist_1_param_1\"]).abs()\n",
        "  err_rel_theta_0 = (err_abs_theta_0 / df_thetas[\"dist_1_param_1\"].abs()).where(df_thetas[\"dist_1_param_1\"] != 0, 0)\n",
        "\n",
        "  err_abs_theta_1 = (theta_1 - df_thetas[\"dist_1_param_2\"]).abs()\n",
        "  err_rel_theta_1 = (err_abs_theta_1 / df_thetas[\"dist_1_param_2\"].abs()).where(df_thetas[\"dist_1_param_2\"] != 0, 0)\n",
        "\n",
        "  tabla0 = tabla0.assign(err_abs_theta_0=err_abs_theta_0,err_rel_theta_0=err_rel_theta_0,err_abs_theta_1=err_abs_theta_1,err_rel_theta_1=err_rel_theta_1)\n",
        "  if dicData[\"method\"] == 'Seleccion':\n",
        "\n",
        "    theta_2 = dicData['dist_2_param_1']\n",
        "    theta_3 = dicData['dist_2_param_2']\n",
        "\n",
        "    err_abs_theta_2 = (theta_2 - df_thetas[\"dist_2_param_1\"]).abs()\n",
        "    err_rel_theta_2 = ((err_abs_theta_2 / df_thetas[\"dist_2_param_1\"].abs()).where((row[\"ID_modelo\"] == \"S0\") & (df_thetas[\"dist_2_param_1\"] != 0),0))\n",
        "\n",
        "    err_abs_theta_3 = (theta_3 - df_thetas[\"dist_2_param_2\"]).abs()\n",
        "    err_rel_theta_3 = ((err_abs_theta_3 / df_thetas[\"dist_2_param_2\"].abs()).where((row[\"ID_modelo\"] == \"S0\") & (df_thetas[\"dist_2_param_2\"] != 0),0))\n",
        "\n",
        "    tabla0 = tabla0.assign(err_abs_theta_2=err_abs_theta_2, err_rel_theta_2=err_rel_theta_2, err_abs_theta_3=err_abs_theta_3, err_rel_theta_3=err_rel_theta_3)\n",
        "\n",
        "  return tabla0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_1FZNTAMHnC"
      },
      "outputs": [],
      "source": [
        "def compute_mean_std_err(media, std, n_muestras, t_ejec, orig_media, orig_std, id):\n",
        "\n",
        "        err_abs_media = abs(media - orig_media)\n",
        "        err_rel_media = err_abs_media / abs(orig_media) if orig_media != 0 else 0.0\n",
        "\n",
        "        err_abs_std = abs(std - orig_std)\n",
        "        err_rel_std = err_abs_std / abs(orig_std) if orig_std != 0 else 0.0\n",
        "\n",
        "        return {\"ID\": id, \"t_ejecucion\": t_ejec,\n",
        "                \"media\": media, \"err_abs_media\": err_abs_media, \"err_rel_media\": err_rel_media,\n",
        "                \"std\": std, \"err_abs_std\": err_abs_std, \"err_rel_std\": err_rel_std,\n",
        "                \"n_muestras\": n_muestras}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr5YSql5Ie5E"
      },
      "outputs": [],
      "source": [
        "def tabla_1(data_props, row, pct_seg=0.00, n_muestras=1000, n_iter=100):\n",
        "\n",
        "    data_props = pd.DataFrame.from_dict(data_props, orient=\"index\")\n",
        "\n",
        "    orig_method = str(row[\"sim_id\"])[0:2]\n",
        "    orig_media = data_props.loc[orig_method, \"media\"]\n",
        "    orig_std = data_props.loc[orig_method, \"std\"]\n",
        "    orig_media_obs = data_props.loc[f'{orig_method}_obs', \"media\"]\n",
        "    orig_std_obs = data_props.loc[f'{orig_method}_obs', \"std\"]\n",
        "    orig_media_aus = data_props.loc[f'{orig_method}_aus', \"media\"]\n",
        "    orig_std_aus = data_props.loc[f'{orig_method}_aus', \"std\"]\n",
        "\n",
        "    medias_Y = []\n",
        "    medias_Yobs = []\n",
        "    medias_Yaus = []\n",
        "\n",
        "    stds_Y = []\n",
        "    stds_Yobs = []\n",
        "    stds_Yaus = []\n",
        "\n",
        "    lens_Y = []\n",
        "    lens_Yobs = []\n",
        "    lens_Yaus = []\n",
        "\n",
        "    for i in range(n_iter):\n",
        "\n",
        "      datos_generados = genera_datos(df=row.to_frame().T, n_muestras=n_muestras)\n",
        "\n",
        "      datos_Y = datos_generados[\"Y\"]\n",
        "      datos_Yobs = datos_generados.loc[datos_generados[\"R\"] == 1, \"Y\"]\n",
        "      datos_Yaus = datos_generados.loc[datos_generados[\"R\"] == 0, \"Y\"]\n",
        "\n",
        "      medias_Y.append(datos_Y.mean())\n",
        "      medias_Yobs.append(datos_Yobs.mean())\n",
        "      medias_Yaus.append(datos_Yaus.mean())\n",
        "\n",
        "      stds_Y.append(datos_Y.std())\n",
        "      stds_Yobs.append(datos_Yobs.std())\n",
        "      stds_Yaus.append(datos_Yaus.std())\n",
        "\n",
        "      lens_Y.append(len(datos_Y))\n",
        "      lens_Yobs.append(len(datos_Yobs))\n",
        "      lens_Yaus.append(len(datos_Yaus))\n",
        "\n",
        "    media_Y = np.mean(medias_Y)\n",
        "    media_Yobs = np.mean(medias_Yobs)\n",
        "    media_Yaus = np.mean(medias_Yaus)\n",
        "\n",
        "    std_Y = np.mean(stds_Y)\n",
        "    std_Yobs = np.mean(stds_Yobs)\n",
        "    std_Yaus = np.mean(stds_Yaus)\n",
        "\n",
        "    len_Y = np.mean(lens_Y)\n",
        "    len_Yobs = np.mean(lens_Yobs)\n",
        "    len_Yaus = np.mean(lens_Yaus)\n",
        "\n",
        "    t_ejec = row[\"time\"]\n",
        "    pct_seg_str = f\"{float(pct_seg):.2f}\"\n",
        "\n",
        "    rows = [\n",
        "        compute_mean_std_err(media_Y, std_Y, len_Y, t_ejec, orig_media, orig_std, f\"{row['ID']}_Y_{pct_seg_str}_seg\"),\n",
        "        compute_mean_std_err(media_Yobs, std_Yobs, len_Yobs, t_ejec, orig_media_obs, orig_std_obs, f\"{row['ID']}_Yobs_{pct_seg_str}_seg\"),\n",
        "        compute_mean_std_err(media_Yaus, std_Yaus, len_Yaus, t_ejec, orig_media_aus, orig_std_aus, f\"{row['ID']}_Yaus_{pct_seg_str}_seg\")\n",
        "    ]\n",
        "\n",
        "    tabla1 = pd.DataFrame(rows).set_index(\"ID\")\n",
        "\n",
        "    return tabla1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTRcw-KiFs1N"
      },
      "outputs": [],
      "source": [
        "def Analiza(dir, resumen_path, out_dir, label, pct_seg=0.00):\n",
        "\n",
        "    path = Path(dir)\n",
        "    dir_sim = path / f\"Simulaciones_{label}\"\n",
        "    gen_path = dir_sim / f\"Gen_{label}.csv\"\n",
        "    data_dir = dir_sim / \"Datos_generados\"\n",
        "    resumen_path = Path(resumen_path)\n",
        "    tablas_dir = Path(out_dir)\n",
        "\n",
        "    for p in [gen_path, data_dir, resumen_path]:\n",
        "        if not p.exists():\n",
        "            raise FileNotFoundError(f\"{p} not found\")\n",
        "\n",
        "    resumen_name = resumen_path.name.lower()\n",
        "    es_seguimiento = (\"seguimiento\" in resumen_name) or (\"_seg\" in resumen_name)\n",
        "    pct_seg_val = float(pct_seg) if es_seguimiento else 0.00\n",
        "    pct_seg_str = f\"{pct_seg_val:.2f}\"\n",
        "\n",
        "    data_props = {}\n",
        "    for csv_file in data_dir.glob(\"*.csv\"):\n",
        "        if \"_seg\" in csv_file.stem:\n",
        "            continue\n",
        "\n",
        "        df = pd.read_csv(csv_file)\n",
        "\n",
        "        datos = df[\"Y\"]\n",
        "        datos_obs = df.loc[df[\"R\"] == 1, \"Y\"]\n",
        "        datos_aus = df.loc[df[\"R\"] == 0, \"Y\"]\n",
        "\n",
        "        data_props[f'{csv_file.stem}'] = {\"n_muestras\":len(datos), \"media\": datos.mean(),\"std\": datos.std()}\n",
        "        data_props[f'{csv_file.stem}_obs'] = {\"n_muestras\":len(datos_obs), \"media\": datos_obs.mean(),\"std\": datos_obs.std()}\n",
        "        data_props[f'{csv_file.stem}_aus'] = {\"n_muestras\":len(datos_aus), \"media\": datos_aus.mean(),\"std\": datos_aus.std()}\n",
        "\n",
        "    gen_csv = pd.read_csv(gen_path)\n",
        "    dicGen = {row[\"sim_id\"]: row.to_dict() for _, row in gen_csv.iterrows()}\n",
        "\n",
        "    resumen = pd.read_csv(resumen_path)\n",
        "    resumen[\"model_method\"] = resumen[\"method\"]\n",
        "    resumen[\"gen_data\"]   = resumen[\"sim_id\"].astype(str).str[0:2]\n",
        "    resumen[\"gen_method\"] = resumen[\"sim_id\"].astype(str).str[1:2].map({\"m\": \"Mezcla\", \"s\": \"Seleccion\"})\n",
        "    resumen[\"ID_modelo\"] = resumen[\"sim_id\"].astype(str).str[3:5]\n",
        "    resumen[\"ID_prior\"]  = resumen[\"sim_id\"].astype(str).str[5:6]\n",
        "    resumen[\"ID\"]        = resumen[\"sim_id\"].astype(str).str[0:6]\n",
        "\n",
        "    for (method, id_model), df_model in resumen.groupby([\"model_method\", \"ID_modelo\"]):\n",
        "\n",
        "        df_model = df_model.reset_index(drop=True)\n",
        "\n",
        "        tablas = []\n",
        "\n",
        "        for _, row in df_model.iterrows():\n",
        "\n",
        "            if row[\"ID_modelo\"] in (\"S0\", \"M0\"):\n",
        "                tabla0 = tabla_0(df_model, dicGen, row)\n",
        "                if tabla0 is not None:\n",
        "                  tabla0.insert(1, \"pct_seg\", pct_seg_str)\n",
        "                  tabla0.to_csv(tablas_dir / f\"{id_model}_tabla0.csv\", index=False)\n",
        "\n",
        "            tablas.append(tabla_1(data_props, row, pct_seg_str))\n",
        "\n",
        "        tabla1 = pd.concat(tablas, ignore_index=False)\n",
        "        tabla1.to_csv(tablas_dir / f\"{id_model}_tabla1.csv\", index=True)\n",
        "\n",
        "    data_props = pd.DataFrame.from_dict(data_props, orient=\"index\")\n",
        "    data_props.to_csv(tablas_dir / \"tabla_datos.csv\", index=True)\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlPztSPPWDhr"
      },
      "source": [
        "# Ejecución"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVSAhy3KOxsU"
      },
      "outputs": [],
      "source": [
        "def ejecuta_completo(dir, label, n_ejecuciones=1, n_iteraciones=1, genera=0, pct=0.15, base=1, seguimiento = 1, updatepriors=1, gibbs=1, seg_updatepriors=1, seg_gibbs=1, P_R=0):\n",
        "\n",
        "  sim_dir = Path(dir) / f\"Simulaciones_{label}\"\n",
        "  datos_path = Path(dir) / f\"Simulaciones_{label}/Gen_{label}.csv\"\n",
        "\n",
        "  if genera == 1:\n",
        "    df = genera_datos(datos_path, pct=pct)\n",
        "    print('Datos generados')\n",
        "\n",
        "  iter_dir = sim_dir / \"Ejecuciones\"\n",
        "  iter_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  try:\n",
        "    Estima_iterativo(dir, label, n_ejecuciones, n_iteraciones, base=base, seguimiento=seguimiento, updatepriors=updatepriors, gibbs=gibbs, seg_updatepriors=seg_updatepriors, seg_gibbs=seg_gibbs, P_R=P_R, pct=pct)\n",
        "  except TypeError as e:\n",
        "    if \"pct\" in str(e):\n",
        "      Estima_iterativo(dir, label, n_ejecuciones, n_iteraciones, base=base, seguimiento=seguimiento, updatepriors=updatepriors, gibbs=gibbs, seg_updatepriors=seg_updatepriors, seg_gibbs=seg_gibbs, P_R=P_R)\n",
        "    else:\n",
        "      raise\n",
        "\n",
        "  analisis_dir = sim_dir/\"Analisis\"\n",
        "  analisis_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  for path in iter_dir.glob(\"*.csv\"):\n",
        "    resumen_path = str(path)\n",
        "    out_path = str(path.name).replace(\"Resumen_\", \"\")\n",
        "    out_dir = analisis_dir / out_path\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "      Analiza(dir, resumen_path, out_dir, label, pct_seg=pct)\n",
        "    except TypeError as e:\n",
        "      if \"pct_seg\" in str(e):\n",
        "        Analiza(dir, resumen_path, out_dir, label)\n",
        "      else:\n",
        "        raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD8kRs9SK7nb"
      },
      "source": [
        "# Simulaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lXLu7HbN7fgr"
      },
      "outputs": [],
      "source": [
        "dir = '/content/drive/MyDrive/TFM/Simulaciones'\n",
        "ejecuta_completo(dir, 'A', n_ejecuciones=10, n_iteraciones=10, genera=1, pct=0.20, P_R=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-EANi0muTxX"
      },
      "outputs": [],
      "source": [
        "dir = '/content/drive/MyDrive/TFM/Simulaciones'\n",
        "ejecuta_completo(dir, 'B', n_ejecuciones=10, n_iteraciones=10, genera=1, pct=0.20, P_R=0.5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "lLjVXggwJvji",
        "omXT2pMCKW7K",
        "xraZXVwSskJ0",
        "-fkTgt6ptgsA",
        "G1ZusgCO3yrc",
        "Cxii22hqtxXe",
        "Jofy7LaZuCO8",
        "rumhEjzHuCGm",
        "_J_mD40DnOTm",
        "bvpGyquhDIpr",
        "ZlmKkKdqldP5",
        "a9FSgU6i8tGz",
        "Ge0XKXdmliK1",
        "VJPu8iJfCjbO",
        "TBGrv-jeygth",
        "hWoR6Qa1DlwC",
        "RlPztSPPWDhr"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}